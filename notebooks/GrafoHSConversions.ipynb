{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d89077e9-add9-40c5-84fc-701287281e57",
   "metadata": {},
   "source": [
    "### (Execute if your running in Binder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ae3cf-a18b-4142-a3d6-190fb46dbe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these lines\n",
    "\n",
    "# !pip install pandas\n",
    "# !pip install openpyxl\n",
    "# !pip install networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fab08c-04ae-4b25-b88d-5c291faa740f",
   "metadata": {},
   "source": [
    "# HS Conversion Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256d55eb-f944-4bff-931f-28ee2f4fb723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import platform\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206108c1-fa38-4e4a-9f5a-3775125a379d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### En desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2f498435-6a3b-4de8-a19d-885d425b06b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import functools\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from operator import and_\n",
    "\n",
    "\n",
    "class HSCorrelations: \n",
    "    \n",
    "    def __init__(self, path=None):\n",
    "        self.__HS = ['HS92', 'HS96', 'HS02', 'HS07', 'HS12', 'HS17'] #should be updated if changed \n",
    "        print(f\"Loading HS Correlation Tables from path provided\")\n",
    "        if path: \n",
    "            self.__data = pd.read_excel(path,\n",
    "                            usecols= self.__HS,\n",
    "                            dtype = {v:'object' for v in self.__HS}).dropna().drop_duplicates()\n",
    "        else:\n",
    "            print(\"Loading HS Correlation Tables from UNSTATS\\n server\")\n",
    "            self.__url = \"https://unstats.un.org/unsd/trade/classifications/tables/CompleteCorrelationsOfHS-SITC-BEC_20170606.xlsx\"\n",
    "            self.__data = pd.read_excel(self.__url,\n",
    "                                usecols= self.__HS,\n",
    "                                dtype = {v:'object' for v in self.__HS}).dropna().drop_duplicates()\n",
    "        print(\"Tables already loaded. Use `available_methods()` for more information\\n\")\n",
    "        \n",
    "    def available_methods(self):\n",
    "        print(\"Use `get_df()` to get dataframe with the correlations between all HS versions\\n\")\n",
    "        print(\"Use `get_codes()` to get the codes by: version (default HS17, str or list) or chapter\") \n",
    "        #uncomplete\n",
    "     \n",
    "    def get_df(self):\n",
    "        return self.__data\n",
    "    \n",
    "    def get_url(self):\n",
    "        return self.__url\n",
    "    \n",
    "    def get_versions(self): \n",
    "        return self.__HS\n",
    "\n",
    "    def get_codes(self, version=\"HS17\", chapter=None): \n",
    "        df = pd.DataFrame(self.__data[version], columns = [version]).drop_duplicates()\n",
    "        if chapter:\n",
    "            df = df[df[version].str.startswith(chapter)]\n",
    "        return df\n",
    "    \n",
    "    def check_position(self, position=None):\n",
    "        if position:\n",
    "            return position in self.__data.values\n",
    "            \n",
    "    \n",
    "    def return_used_versions(self, start_year=None, end_year=None):\n",
    "        if start_year==None: \n",
    "            start_year = 1992\n",
    "        if end_year==None: \n",
    "            end_year = datetime.now().year\n",
    "        if start_year < 1992 or end_year<start_year or end_year>datetime.now().year: \n",
    "            print(\"Uncorrect years\")\n",
    "        years = [1992, 1996, 2002, 2007, 2012, 2017]\n",
    "        version_dict = {k:v for k,v in zip(years, self.__HS)}\n",
    "        start_v = functools.reduce(lambda a,b: a if a<=start_year else b, list(reversed(years)))\n",
    "        end_v = functools.reduce(lambda a,b: a if a<=end_year else b, list(reversed(years)))\n",
    "        years_list = years[years.index(start_v):years.index(end_v)+1]\n",
    "        return [version_dict[x] for x in years_list]\n",
    "    \n",
    "    def filter_df(self, positions=None, start_year=None, end_year=None): \n",
    "        \n",
    "        cols = self.return_used_versions(start_year, end_year)\n",
    "        df = self.__data[cols]\n",
    "        if positions:\n",
    "            filters = [(df[col].isin(positions)) for col in cols]\n",
    "            mask = functools.reduce(and_, filters, True)\n",
    "            return df[mask].drop_duplicates().reset_index(drop=True)\n",
    "        else:\n",
    "            return df         \n",
    "            \n",
    "    def find_homogeneous_serie(self, position=None, start_year=None, end_year=None):\n",
    "        if self.check_position(position): \n",
    "            cols = self.return_used_versions(start_year, end_year)\n",
    "            data = self.filter_df(start_year, end_year)\n",
    "            versions = [v for v in cols if data[v].str.contains(position).any()]\n",
    "            for col in cols:\n",
    "                data[col] = data[col].apply(lambda x: col+\"-\"+str(int(x)).zfill(6))\n",
    "            connections = []\n",
    "            for i in range(len(cols)-1): \n",
    "                temp_tup_list = list(data[[cols[i], cols[i+1]]].drop_duplicates().itertuples(index=False, name=None))\n",
    "                connections = connections + temp_tup_list \n",
    "            G = nx.Graph()\n",
    "            G.add_edges_from(connections)\n",
    "            positions = sorted(nx.node_connected_component(G, versions[-1]+\"-\"+position))\n",
    "            return positions\n",
    "        else:\n",
    "            print(\"Please define a correct position\")\n",
    "    \n",
    "    def genSankey(self, position=None, start_year=None, end_year=None, output_title='Sankey Diagram'):\n",
    "        if self.check_position(position): \n",
    "            related = list(set([x[5:] for x in self.find_homogeneous_serie(position, start_year, end_year)]))\n",
    "            cat_cols = self.return_used_versions(start_year, end_year)\n",
    "            df = self.filter_df(related, start_year, end_year)\n",
    "            df['count'] = 1\n",
    "            for col in cat_cols: \n",
    "                df[col] = df[col].apply(lambda x: col+\"-\"+str(int(x)).zfill(6))\n",
    "            colorPalette = ['#4B8BBE','#306998','#FFE873','#FFD43B','#646464',\"#002060\"]\n",
    "            labelList = []\n",
    "            colorNumList = []\n",
    "            for catCol in cat_cols:\n",
    "                labelListTemp =  list(set(df[catCol].values))\n",
    "                colorNumList.append(len(labelListTemp))\n",
    "                labelList = labelList + labelListTemp\n",
    "\n",
    "            # remove duplicates from labelList\n",
    "            labelList = list(dict.fromkeys(labelList))\n",
    "\n",
    "            # define colors based on number of levels\n",
    "            colorList = []\n",
    "            for idx, colorNum in enumerate(colorNumList):\n",
    "                colorList = colorList + [colorPalette[idx]]*colorNum\n",
    "\n",
    "            # transform df into a source-target pair\n",
    "            for i in range(len(cat_cols)-1):\n",
    "                if i==0:\n",
    "                    sourceTargetDf = df[[cat_cols[i],cat_cols[i+1],'count']]\n",
    "                    sourceTargetDf.columns = ['source','target','count']\n",
    "                else:\n",
    "                    tempDf = df[[cat_cols[i],cat_cols[i+1],'count']]\n",
    "                    tempDf.columns = ['source','target','count']\n",
    "                    sourceTargetDf = pd.concat([sourceTargetDf,tempDf])\n",
    "\n",
    "            sourceTargetDf = sourceTargetDf.groupby(['source','target']).agg({'count':'sum'}).reset_index()\n",
    "\n",
    "            # add index for source-target pair\n",
    "            sourceTargetDf['sourceID'] = sourceTargetDf['source'].apply(lambda x: labelList.index(x))\n",
    "            sourceTargetDf['targetID'] = sourceTargetDf['target'].apply(lambda x: labelList.index(x))\n",
    "\n",
    "            # creating the sankey diagram\n",
    "            data = dict(\n",
    "                type='sankey',\n",
    "                node = dict(\n",
    "                  pad = 15,\n",
    "                  thickness = 20,\n",
    "                  line = dict(\n",
    "                    color = \"black\",\n",
    "                    width = 0.5\n",
    "                  ),\n",
    "                  label = labelList,\n",
    "                  color = colorList\n",
    "                ),\n",
    "                link = dict(\n",
    "                  source = sourceTargetDf['sourceID'],\n",
    "                  target = sourceTargetDf['targetID'],\n",
    "                  value = sourceTargetDf['count']\n",
    "                )\n",
    "              )\n",
    "\n",
    "            layout =  dict(\n",
    "                title = output_title,\n",
    "                font = dict(\n",
    "                  size = 15\n",
    "                )\n",
    "            )\n",
    "\n",
    "            fig = dict(data=[data], layout=layout)\n",
    "            return fig\n",
    "        else: \n",
    "           print(\"Please define a correct position\") \n",
    "    \n",
    "    def recursive_trade_off(df, position, k): \n",
    "    \n",
    "        if k>=0:\n",
    "            currcols = df.columns.tolist()[k:]\n",
    "            print(f\"Evaluating graph object with {','.join(currcols)} versions\\n\")\n",
    "            data = df[currcols].drop_duplicates()\n",
    "            connections = []\n",
    "            for i in range(len(currcols)-1): \n",
    "                temp_tup_list = list(data[[currcols[i], currcols[i+1]]].drop_duplicates().itertuples(index=False, name=None))\n",
    "                connections = connections + temp_tup_list\n",
    "            G = nx.Graph()\n",
    "            G.add_edges_from(connections)\n",
    "            try:\n",
    "                positions = sorted(nx.node_connected_component(G, currcols[-1]+\"-\"+position))\n",
    "                if len(positions)==len(currcols): \n",
    "                    return recursive_trade_off(df, position, k-1)\n",
    "                else: \n",
    "                    print(\"Evaluation finished\\n\")\n",
    "                    print(f\"The {','.join(currcols[1:])} versions support your position with no precision loss\")\n",
    "            except:\n",
    "                print(f\"Position {position} not founded\")\n",
    "        else:\n",
    "            print(f\"The {','.join(df.columns.tolist())} versions support your position with no precision loss\")\n",
    "        \n",
    "    def trade_off(self, position=None, start_year=None, end_year=None):\n",
    "        if start_year==None: \n",
    "            start_year = 1992\n",
    "        if end_year==None: \n",
    "            end_year = datetime.now().year\n",
    "        if start_year < 1992 or end_year<start_year or end_year>datetime.now().year: \n",
    "            print(\"Uncorrect years\")\n",
    "\n",
    "        if self.ckeck_position(position): \n",
    "            versions = self.return_used_versions(start_year, end_year)\n",
    "            print(f\"Period between {start_year} and {end_year} contains the {','.join(versions)} versions\\n\") \n",
    "            print(f\"Loading HS Correlations Tables\\n\")\n",
    "            versions = [v for v in versions if self.__data[v].str.contains(position).any()]\n",
    "\n",
    "            if len(versions)>0: \n",
    "                print(f\"The position {position} was included in the {','.join(versions)} versions\\n\")\n",
    "                data = self.__data[versions].drop_duplicates()\n",
    "                for col in data.columns:\n",
    "                    data[col] = data[col].apply(lambda x: col+\"-\"+str(int(x)).zfill(6))\n",
    "                k=len(versions)-2\n",
    "                print(f\"Evaluating maximum period with no precision loss for position {position}\\n\")\n",
    "                return recursive_trade_off(data, position, k)\n",
    "            else:\n",
    "                print(f\"Position {position} not founded in that period\")\n",
    "        else:\n",
    "            print(\"Please define a correct position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "186272f4-1b9a-41de-be74-eaa1ffad6728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HS Correlation Tables from path provided\n",
      "Tables already loaded. Use `available_methods()` for more information\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fullpath = 'C:\\\\Users\\\\Usuario\\\\Desktop\\\\CEP\\\\HSConversionTables\\\\data\\\\CompleteCorrelationsOfHS-SITC-BEC_20170606.xlsx'\n",
    "a = HSCorrelations(path = fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bcc7627b-efaf-44ca-b81f-9bf09ba6145f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(a.check_position(\"010130\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8cc5b01a-5280-4e18-a4d4-c60f21c9b53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS92</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>020110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>020120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>020130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>020210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>020220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>020230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>020311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>020312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>020319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>020321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>020322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>020329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>020410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>020421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>020422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>020423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>020430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>020441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>020442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>020443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>020450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>020610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>020621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>020622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>020629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>020630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>020641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>020649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>020680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>020690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>020710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>020721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>020739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>020741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>020750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>020722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>020742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>020723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>020731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>020743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>020810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>020820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>020890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>020900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>021011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>021012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>021019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>021020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>021090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HS92\n",
       "67   020110\n",
       "68   020120\n",
       "69   020130\n",
       "70   020210\n",
       "71   020220\n",
       "72   020230\n",
       "73   020311\n",
       "74   020312\n",
       "75   020319\n",
       "76   020321\n",
       "77   020322\n",
       "78   020329\n",
       "79   020410\n",
       "80   020421\n",
       "81   020422\n",
       "82   020423\n",
       "83   020430\n",
       "84   020441\n",
       "85   020442\n",
       "86   020443\n",
       "87   020450\n",
       "88   020500\n",
       "89   020610\n",
       "90   020621\n",
       "91   020622\n",
       "92   020629\n",
       "93   020630\n",
       "94   020641\n",
       "95   020649\n",
       "96   020680\n",
       "97   020690\n",
       "98   020710\n",
       "99   020721\n",
       "100  020739\n",
       "101  020741\n",
       "103  020750\n",
       "106  020722\n",
       "108  020742\n",
       "115  020723\n",
       "118  020731\n",
       "123  020743\n",
       "135  020810\n",
       "136  020820\n",
       "142  020890\n",
       "154  020900\n",
       "156  021011\n",
       "157  021012\n",
       "158  021019\n",
       "159  021020\n",
       "160  021090"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_codes(version=\"HS92\", chapter=\"02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "37614c77-7a28-43dd-8470-f4fe680d4ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HS92', 'HS96', 'HS02', 'HS07', 'HS12', 'HS17']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d87ab62-b17c-4dca-866a-4c42dea2ba9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HS02', 'HS07', 'HS12', 'HS17']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.return_used_versions(2006,2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ab22063-06f1-4c04-a32e-74787d80c26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS92</th>\n",
       "      <th>HS96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010111</td>\n",
       "      <td>010111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010111</td>\n",
       "      <td>010111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HS92    HS96\n",
       "0  010111  010111\n",
       "1  010111  010111"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.filter_df([\"010111\"], 1993, 1996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b9731e75-2ddf-4f2b-9443-b79fc95a1cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HS02-010110',\n",
       " 'HS02-010190',\n",
       " 'HS07-010110',\n",
       " 'HS07-010190',\n",
       " 'HS12-010121',\n",
       " 'HS12-010129',\n",
       " 'HS12-010130',\n",
       " 'HS12-010190',\n",
       " 'HS17-010121',\n",
       " 'HS17-010129',\n",
       " 'HS17-010130',\n",
       " 'HS17-010190',\n",
       " 'HS92-010111',\n",
       " 'HS92-010119',\n",
       " 'HS92-010120',\n",
       " 'HS96-010111',\n",
       " 'HS96-010119',\n",
       " 'HS96-010120']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.find_homogeneous_serie(\"010130\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b46611b5-944f-403d-8b88-bc7e6531721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import chart_studio.plotly as py\n",
    "import plotly\n",
    "\n",
    "fig = a.genSankey(\"010130\")\n",
    "if fig is not None:\n",
    "    plotly.offline.plot(fig, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a37ac887-4787-4d45-a357-9b050752b599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period between 2018 and 2019 contains the HS17 versions\n",
      "\n",
      "Loading HS Correlations Tables\n",
      "\n",
      "The position 010130 was included in the HS17 versions\n",
      "\n",
      "Evaluating maximum period with no precision loss for position 010130\n",
      "\n",
      "The HS17 versions support your position with no precision loss\n"
     ]
    }
   ],
   "source": [
    "a.trade_off(\"010130\", 2018, 2019) #corregir que devuelva los años posibles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
